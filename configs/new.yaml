defaults:
  - trainer: base
model:
  wo_merge: false
  agg_func: sum
  learning_rate: 0.0005
  sched_milestones:
  - 7
  - 17
  sched_factor: 0.5
  smpl_init: true
  is_continue: false
  use_body_parsing: false
  with_bkgd: true
  using_inpainting: false
  use_smpl_deformer: true
  use_bbox_sampler: false
  sdf_bounding_sphere_radius: 3
  persons_count: 2
  implicit_network:
    feature_vector_size: 256
    d_in: 3
    d_out: 1
    dims:
    - 256
    - 256
    - 256
    - 256
    - 256
    - 256
    - 256
    - 256
    init: geometry
    bias: 0.6
    skip_in:
    - 4
    weight_norm: true
    embedder_mode: fourier
    multires: 6
    cond: smpl
    scene_bounding_sphere: 4.0
  rendering_network:
    feature_vector_size: 256
    mode: pose
    d_in: 14
    d_out: 3
    dims:
    - 256
    - 256
    - 256
    - 256
    weight_norm: true
    multires_view: -1
  bg_implicit_network:
    feature_vector_size: 256
    d_in: 4
    d_out: 1
    dims:
    - 256
    - 256
    - 256
    - 256
    - 256
    - 256
    - 256
    - 256
    init: none
    bias: 0.0
    skip_in:
    - 4
    weight_norm: false
    embedder_mode: fourier
    multires: 10
    cond: frame
    dim_frame_encoding: 32
  bg_rendering_network:
    feature_vector_size: 256
    mode: nerf_frame_encoding
    d_in: 3
    d_out: 3
    dims:
    - 128
    weight_norm: false
    multires_view: 4
    dim_frame_encoding: 32
  shadow_network:
    d_in: 3
    d_out: 1
    dims:
    - 128
    - 128
    weight_norm: false
  density:
    params_init:
      beta: 0.1
    beta_min: 0.0001
  ray_sampler:
    near: 0.0
    N_samples: 64
    N_samples_eval: 128
    N_samples_extra: 32
    eps: 0.1
    beta_iters: 10
    max_total_iters: 5
    N_samples_inverse_sphere: 32
    add_tiny: 1.0e-06
  loss:
    eikonal_weight: 0.1
    bce_weight: 0.005
    opacity_sparse_weight: 0.1
    in_shape_weight: 0.1
    sdf_loss_weight: 0.01
    dynamic_weight: False

dataset:
  base_ff_config: &base_ff_config
    _target: reconstruction.neuralbody.datasets.factory.CachedFFGenerator
    ff_path: //home/vr/dev/user/6f188a93-f8da-4728-8aaa-ebdba94e2925/frames_folder__2T_A-GgSTzS2HNKq8EoPzg
    frames: ${range:19004,19034, 4}
    generator_caching: true
    save_locally: true
    individulally_iterated_instances: [0,1]
    per_instance_colors: [255, 255]
    mask_threshold: 125
    segmentation_mask_artifact_variant: maskformer
    permute_cameras: false
    permute_frames: none
    resize_ratio: 1.0
    object_source: smpl_proto
  metainfo:
    genders: [male, male]
    frames_count: ${len:${..base_ff_config.frames}}
    subject: ${..base_ff_config.ff_path}
  train:
    type: FFCache
    batch_size: 1
    drop_last: false
    shuffle: true
    worker: 0
    num_sample: 2048
    mask_threshold: 0
    pixel_per_batch: 2048
    correct_translations: false
    chosen_frame_ids: ${..base_ff_config.frames}
    ff_config:
      <<: *base_ff_config
      cameras: [CAM_02, CAM_03, CAM_04, CAM_05, CAM_06, CAM_07, CAM_08, CAM_09, CAM_10,CAM_11,CAM_12,CAM_13,CAM_14, CAM_16, CAM_17]

  valid:
    - type: FFCache
      batch_size: 1
      drop_last: false
      shuffle: false
      worker: 0
      num_sample: -1
      pixel_per_batch: 2048
      mask_threshold: 0
      correct_translations: false
      chosen_frame_ids: [19004, 19008]
      ff_config:
        <<: *base_ff_config
        resize_ratio: 0.125
        cameras: [CAM_02, CAM_05]

seed: 42
project_name: model_w_bg
exp: looks-like-it-works-3
run: ${dataset.metainfo.subject}